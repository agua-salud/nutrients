---
title: "2 Data Set Preparation"
description: |
  Workflow for preparation  of the **16S rRNA** and **ITS** data sets. These steps are needed before analyzing the data. In this workflow, sample groups are defined, and phyloseq objects are created and curated.
author:
#  - name: Jarrod J Scott
#    url: https://example.com/norajones
#    affiliation: Spacely Sprockets
#    affiliation_url: https://example.com/spacelysprokets
bibliography: assets/cite.bib
---

<details markdown="1">
<summary><strong>Click here</strong> for setup information.</summary>

```{r setup, message=FALSE, results = 'hide'}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
set.seed(119)
#library(conflicted)
#pacman::p_depends(ape, local = TRUE)  
#pacman::p_depends_reverse(ape, local = TRUE)  
library(phyloseq); packageVersion("phyloseq")
library(Biostrings); packageVersion("Biostrings")
pacman::p_load(tidyverse, DT, microbiome, taxa, formatR,
               captioner, reactable, downloadthis,
               metacoder, ampvis2, ape, statnet.common, 
               install = FALSE, update = FALSE)

options(scipen=999)
knitr::opts_current$get(c(
  "cache",
  "cache.path",
  "cache.rebuild",
  "dependson",
  "autodep"
))
```

```{r, echo=FALSE, eval=TRUE}
xaringanExtra::use_panelset()
```

```{r, message=FALSE, results = 'hide', eval=TRUE}
remove(list = ls())
```

```{r, message=FALSE, results = 'hide', eval=TRUE}
### COmmon formatting scripts
### NOTE: captioner.R must be read BEFORE captions_XYZ.R
source("assets/captioner/captioner.R")
source("assets/captioner/captions/captions_data_prep_ssu.R")
source("assets/reactable/download_this_fun.R")
source("assets/reactable/styles.R")
source("assets/reactable/table_functions/data_prep.R")
```

</details>

```{r, include=FALSE, eval=TRUE}
## ONLY FOR PAGE BUILD
load("page_build/data_prep_ssu_wf.rdata")

## READ IN all phyloseq objects
ps <- readRDS("files/data-prep/rdata/ssu_ps.rds")
ps_no_low <- readRDS("files/data-prep/rdata/ssu_ps_no_low.rds")
ps_no_mito <- readRDS("files/data-prep/rdata/ssu_ps_no_mito.rds")
ps_no_euk <- readRDS("files/data-prep/rdata/ssu_ps_no_euk.rds")
ps_filt <- readRDS("files/data-prep/rdata/ssu_ps_filt.rds")
ps_work_o <- readRDS("files/data-prep/rdata/ssu_ps_work_o.rds")
ps_work <- readRDS("files/data-prep/rdata/ssu_ps_work.rds")
ps_no_chloro <- readRDS("files/data-prep/rdata/ssu_ps_no_chloro.rds")
objects()
```

These workflows share many common variable names so you must split the workflow into a script for each data set OR run the command `remove(list = ls())` before beginning the next workflow.

# 16s rRNA Data

## Prerequisites

In order to run this workflow, you eith#er need to run the corresponding [DADA2 Workflow for 2018 16S rRNA](agua-dada2.html#s-rrna-data) or begin with the output from that workflow, `data_prep_ssu_wf.rdata`. See the [Data Availability](data-availability.html) page for complete details.

Unless otherwise noted, we primarily use [phyloseq](https://joey711.github.io/phyloseq/)  [@mcmurdie2013phyloseq] in this section of the workflow to prepare the 2018 16S rRNA data set for community analyses. We prepare the data set by curating samples, removing contaminants, and creating phyloseq objects.

## Sample Summary

Before we begin, let's create a summary table containing some basic sample metadata and the read count data from the [DADA2 workflow](dada2-agua.html#s-rrna-data.html). We need to inspect how total reads changed through the workflow. While we are at it, let's create more intuitive Sample IDs. For more details on how reads changed at each step of the workflow, see the [summary table](dada2-agua.html#track-reads-through-workflow) at the end of the DADA2 section. Table headers are as follows:

| Header            | Description                                                                                    |
|-------------------|------------------------------------------------------------------------------------------------|
| `Sample ID`       | the new sample ID based on Location + Site + Transect + Sampling Year + Forest Age + Treatment |
| `FastqID`         | base name of the fastq file                                                                    |
| `Location`        | Primary sampling location                                                                      |
| `Site`            | within location site                                                                           |
| `Transect`        | within site transect                                                                           |
| `Year`            | the year of sampling (Y0, Y1,  Y4)                                                             |
| `forest age code` | Forest age category (NEW, YNG, OLD)                                                            |
| `Forest age`      | maturity of forest stand                                                                       |
| `Treatment`       | control, +N, +P, or +NP                                                                        |
| `input reads`     | Total number of reads at start of dada2 pipeline                                               |
| `final reads`     | Total number of reads at end of dada2 pipeline                                                 |
| `perc_remain`     | percent of reads remaining from `input` to `final`                                             |
| `no. ASVs`        | Total number of ASVs at end of dada2 pipeline                                                  |

<br/>

```{r, echo=FALSE, eval=FALSE}
remove(list = ls())
tmp_tab1 <- read.table(
  "files/dada2/tables/ssu_sample_seq_info.txt", header = TRUE, sep = "\t")
tmp_tab1$root <- gsub("_.*", "", tmp_tab1$Fastq_ID_Forward)
tmp_tab2 <- read.table(
  "files/dada2/tables/ssu_read_changes.txt", header = TRUE,  sep = "\t")
tmp_tab <- left_join(tmp_tab1, tmp_tab2, by = c("Sample_ID"))
tmp_tab$New_ID <- base::paste(tmp_tab$loc_code,
                                   tmp_tab$Site, sep = "_")
tmp_tab$New_ID <- base::paste(tmp_tab$New_ID,
                                   tmp_tab$Transect, sep = "_")
tmp_tab$New_ID <- base::paste(tmp_tab$New_ID,
                                   tmp_tab$year_code, sep = "_")
tmp_tab$New_ID <- base::paste(tmp_tab$New_ID,
                                    tmp_tab$forest_age_code, sep = "_")
tmp_tab$New_ID <- base::paste(tmp_tab$New_ID,
                                   tmp_tab$Treatment, sep = "_")
tmp_tab[duplicated(tmp_tab[,c('New_ID')]),]
tmp_tab <- tmp_tab %>% tibble::column_to_rownames("New_ID")
tmp_tab$Sample_ID <- NULL
tmp_tab <- tmp_tab %>% tibble::rownames_to_column("Sample_ID")

tmp_tab[, c(6, 9:13, 15, 18:(ncol(tmp_tab)-2))] <- NULL
tmp_tab <- tmp_tab[, c(1,9,2,5,3,10,8,4,6,7,11,12)]
load("files/dada2/rdata/ssu_dada2_wf.rdata")
tmp_df <- data.frame(seqtab)
tmp_asv <- data.frame(rowSums(tmp_df[] > 0))
tmp_asv <- tmp_asv %>% tibble::rownames_to_column("root") %>%
  dplyr::rename("total_asvs" = 2)
tmp_tab2 <- left_join(tmp_tab, tmp_asv, by = c("root"))
tmp_tab2 <- tmp_tab2 %>% dplyr::rename("FastqID" = 2, "Year" = 6)

write.table(tmp_tab2, "files/data-prep/tables/ssu_summary_table.txt", quote = FALSE, sep = "\t", row.names = FALSE)
rm(list = ls(pattern = "tmp_"))
```


```{r, echo=FALSE, eval=TRUE}
joined_tab <- read.table("files/data-prep/tables/ssu_summary_table.txt", header = TRUE)
ssu_summary_table <- read.table("files/data-prep/tables/ssu_summary_table.txt", header = TRUE)
```

<small>`r caption_tab_ssu("ssu_summary_table")`</small>

```{r eval=TRUE, echo=FALSE, layout="l-page"}
download_this_fun(ssu_summary_table)
```

```{r, echo=FALSE, layout="l-page", eval=TRUE}
sample_summary_table(seq_table)
rm(seq_table)
```

## Defining Groups

1. Load the data packet produced in the final step of the DADA2 workflow. This packet (`ssu_dada2_wf.rdata`) contains the ASV-by-sample table and the ASV taxonomy table.

2. Rename the samples so names have plot and Depth info.

3. After we load the data packet, we next need to format sample names and define groups.

```{r}
#tmp_tab <- joined_tab[order(joined_tab$FastqID), ]
identical(joined_tab$FastqID, rownames(seqtab))
tmp_new_names <- joined_tab$Sample_ID
rownames(seqtab) <- tmp_new_names

samples.out <- rownames(seqtab)

sample_name <- substr(samples.out, 1, 999)
loc <- substr(samples.out, 0, 2)
site <- substr(samples.out, 4, 6)
tran <- substr(samples.out, 8, 11)
year <- substr(samples.out, 13, 14)
age <- substr(samples.out, 16, 18)
treat <- substr(samples.out, 20, 999)
```

Here is a breakdown of the samples based on the new name: 

- **`r length(unique(sample_name))`** samples.   
- **`r length(unique(loc))`** locations.   
- **`r length(unique(site))`** sites.  
- **`r length(unique(tran))`** transects.  
- **`r length(unique(year))`** sample years.  
- **`r length(unique(age))`** forest ages.   
- **`r length(unique(treat))`** different nutrient treatments.  

We can also take a look at the number of samples per metadata category. 

```{r, echo=FALSE}
tmp_year <- data.frame(table(joined_tab$Year))
tmp_year$type <- "Year"
tmp_site <- data.frame(table(joined_tab$Site))
tmp_site$type <- "Site"
tmp_trans <- data.frame(table(joined_tab$Transect))
tmp_trans$type <- "Transect"
tmp_loc <- data.frame(table(joined_tab$Location))
tmp_loc$type <- "Location"
tmp_treat <- data.frame(table(joined_tab$Treatment))
tmp_treat$type <- "Treatment"
tmp_age <- data.frame(table(joined_tab$Forest_age))
tmp_age$type <- "Forest_age"

md_summary <- rbind(tmp_year, tmp_loc, tmp_treat, tmp_age, tmp_site, tmp_trans)
md_summary <- md_summary[,c(3,1,2)]
md_summary <- md_summary %>% dplyr::rename("variable" = 2) %>% 
                             dplyr::rename(., "category" = 1) %>% 
                             dplyr::rename(., "count" = 3)
```

<br/>

```{r, echo=FALSE, eval=TRUE}
ssu_metadata_summary <- md_summary 
```

<small>`r caption_tab_ssu("ssu_metadata_summary")`</small>

```{r eval=TRUE, echo=FALSE, layout="l-body"}
download_this_fun(ssu_metadata_summary)
```

```{r, echo=FALSE, layout="l-body", eval=TRUE}
metadata_summary_table(seq_table)
rm(seq_table)
```

4. And finally we define a sample data frame that holds the different groups we extracted from the sample names.

```{r}
#define a sample data frame
samdf <- data.frame(SamName = sample_name,
                    LOC = loc,
                    SITE = site,
                    TRAN = tran,
                    YEAR = year,
                    AGE = age,
                    TREAT = treat)
rownames(samdf) <- samples.out
```

## Create a Phyloseq Object

**A**. The first step is to rename the amplicon sequence variants (ASVs) so the designations are a bit more user friendly. By default, DADA2 names each ASV by its unique sequence so that data can be directly compared across studies (which is great). But this convention can get cumbersome downstream, so we rename the ASVs using a simpler convention---ASV1, ASV2, ASV3, and so on.

<aside>
A phyloseq object contains ASV table (taxa abundances), sample metadata, and taxonomy table (mapping between ASVs and higher-level taxonomic classifications).
</aside>

```{r}
# this create the phyloseq object
ps <- phyloseq(otu_table(seqtab, taxa_are_rows = FALSE),
                   sample_data(samdf), tax_table(tax_silva))
tax_table(ps) <- cbind(tax_table(ps),
                           rownames(tax_table(ps)))

# adding unique ASV names
taxa_names(ps) <- paste0("ASV", seq(ntaxa(ps)))
tax_table(ps) <- cbind(tax_table(ps),
                           rownames(tax_table(ps)))
```

So the complete data set contains `r ntaxa(ps)` ASVs. We can also use the [microbiome R package](https://github.com/microbiome/microbiome/)  [@lahti2017microbiome] to get some additional summary data from the phyloseq object.

```{r, echo=FALSE}
min_read_ps <- min(readcount(ps))
max_read_ps <- max(readcount(ps))
total_reads_ps <- sum(readcount(ps))
mean_reads_ps <- round(mean(readcount(ps)), digits = 0)
median_reads_ps <- median(readcount(ps))
total_asvs_ps <- ntaxa(ps)
singleton_ps <- tryCatch(ntaxa(rare(ps, detection = 1, prevalence = 0)), error=function(err) NA)
singleton_ps_perc <- tryCatch(round((100*(ntaxa(rare(ps, detection = 1, prevalence = 0)) /
                                   ntaxa(ps))), digits = 3), error=function(err) NA)
sparsity_ps <- round(length(which(abundances(ps) == 0))/length(abundances(ps)),
                     digits = 3)
```

| Metric                              | Results                                              |
|-------------------------------------|------------------------------------------------------|
| Min. number of reads                | `r min_read_ps`                                      |
| Max. number of reads                | `r max_read_ps`                                      |
| Total number of reads               | `r total_reads_ps`                                   |
| Average number of reads             | `r mean_reads_ps`                                    |
| Median number of reads              | `r median_reads_ps`                                  |
| Sparsity                            | `r sparsity_ps`                                      |
| Any ASVs sum to 1 or less?          | `r isTRUE(singleton_ps >= 1)`                        |
| Number of singleton ASVs            | `r singleton_ps`                                     |
| Percent of ASVs that are singletons | `r singleton_ps_perc`                                |
| Number of sample variables are:     | `r length(sample_data(ps))`    (`r colnames(samdf)`) |

**B**. Add two final columns containing the ASV sequences and ASV IDs. This will be useful later when trying to export a fasta file. We can also take a look at the phyloseq object.

```{r}
colnames(tax_table(ps)) <- c("Kingdom", "Phylum", "Class", "Order",
    "Family", "Genus", "ASV_SEQ", "ASV_ID")
ps
```

```{r, echo=FALSE, eval=TRUE}
ps
```

**C**. Export sequence and taxonomy tables for the unadulterated phyloseq object for later use. We will use the prefix `full` to indicate that these are the *raw* outputs.

```{r}
write.table(tax_table(ps),
            "files/data-prep/tables/ssu_full_tax_table.txt",
            sep="\t", quote = FALSE, col.names=NA)
write.table(t(otu_table(ps)),
            "files/data-prep/tables/ssu_full_seq_table.txt",
            sep="\t", quote = FALSE, col.names=NA)
saveRDS(ps, "files/data-prep/rdata/ssu_ps.rds")
```

## Remove Low-Count Samples

Next, we can remove samples with low read counts---here we use 50,000 reads as the cutoff.

```{r, results = 'markdown'}
ps_no_low <- prune_samples(sample_sums(ps) > 50000, ps)
```

We lost **`r nsamples(ps) - nsamples(ps_no_low)`** sample(s). After removing samples we need to check whether any ASVs ended up with no reads.

```{r}
no_reads <- taxa_sums(ps_no_low) == 0
```

And we lost **`r sum(no_reads)`** ASV(s). So now we must remove these from the ps object.

```{r}
ps_no_low <- prune_taxa(taxa_sums(ps_no_low) > 0, ps_no_low)
saveRDS(ps_no_low, "files/data-prep/rdata/ssu_ps_no_low.rds")
```

```{r, eval=TRUE}
ps_no_low
```

## Remove Contaminants & Unwanted Tax

Let's see if we have any potential contaminants. We can use some [inline R code](https://rmarkdown.rstudio.com/lesson-4.html) to see the taxonomy table for any taxa of interest.

<aside>
The code (hidden by default) is written as `` `r
"Chloroplast" %in% tax_table(ps)` ``.
</aside>

- Are Mitochondria present? `r "Mitochondria" %in% tax_table(ps)`
- Are Chloroplast present? `r "Chloroplast" %in% tax_table(ps)`
- Are Eukaryota present? `r "Eukaryota" %in% tax_table(ps)`

```{r, echo=FALSE}
"Mitochondria" %in% tax_table(ps_no_low)
"Chloroplast" %in% tax_table(ps_no_low)
"Eukaryota" %in% tax_table(ps_no_low)
```

Let's remove these taxa---Eukaryota because we used bacterial/archaeal primers, Mitochondria because those are likely from  eukaryotes, and Chloroplast because those are likely from plants. We must do each of these in turn using phyloseq and it gets a little messy.

Why messy? The `subset_taxa` command removes anything that is `NA` for the specified taxonomic level or above. For example, lets say you run the `subset_taxa` command using `Family != "Mitochondria`". Seems like you should get a phyloseq object with everything except Mitochondria. But actually the command not only gets rid of Mitochondria but everything else that has `NA` for Family and above. In my experience this is not well documented and I had to dig through the files to figure out what was happening.

Anyway, to remove the taxa we do the following:

* Subset the taxa and generate a `ps` object of just the taxa of interest,
* Select the ASV column only, turn it into a factor, and use this to remove <INSERT TAXA> from the `ps` object.

### Remove  Mitochondria ASVs

Remember the original data set contained `r ntaxa(ps_no_low)` ASVs. Here we generate a file with mitochondria ASVs only.

```{r}
tmp_MT1 <- subset_taxa(ps_no_low, Family == "Mitochondria")
tmp_MT1 <-  as(tax_table(tmp_MT1), "matrix")
tmp_MT1 <- tmp_MT1[, 8]
tmp_MT1df <- as.factor(tmp_MT1)
tmp_goodTaxa <- setdiff(taxa_names(ps_no_low), tmp_MT1df)
ps_no_mito <- prune_taxa(tmp_goodTaxa, ps_no_low)
ps_no_mito
saveRDS(ps_no_mito, "files/data-prep/rdata/ssu_ps_no_mito.rds")
```

```{r echo=FALSE, eval=TRUE}
ps_no_mito
```

Looks like this removed **`r ntaxa(ps_no_low) - ntaxa(ps_no_mito)` Mitochondria ASVs**. We will duplicate the code block to remove other groups.

### Remove Chloroplast ASVs

And again with Chloroplast ASVs only.

```{r}
tmp_CH1 <- subset_taxa(ps_no_mito, Order == "Chloroplast")
tmp_CH1 <-  as(tax_table(tmp_CH1), "matrix")
tmp_CH1 <- tmp_CH1[, 8]
tmp_CH1df <- as.factor(tmp_CH1)
tmp_goodTaxa <- setdiff(taxa_names(ps_no_mito), tmp_CH1df)
ps_no_chloro <- prune_taxa(tmp_goodTaxa, ps_no_mito)
saveRDS(ps_no_chloro, "files/data-prep/rdata/ssu_ps_no_chloro.rds")
ps_no_chloro
```

```{r echo=FALSE, eval=TRUE}
ps_no_chloro
```

The code removed an additional **`r ntaxa(ps_no_mito) - ntaxa(ps_no_chloro)` Chloroplast ASVs**.

### Remove Eukaryota ASVs

And again with Eukaryota ASVs only.

```{r}
tmp_EU1 <- subset_taxa(ps_no_chloro, Kingdom == "Eukaryota")
tmp_EU1 <-  as(tax_table(tmp_EU1), "matrix")
tmp_EU1 <- tmp_EU1[, 8]
tmp_EU1df <- as.factor(tmp_EU1)
tmp_goodTaxa <- setdiff(taxa_names(ps_no_chloro), tmp_EU1df)
ps_no_euk <- prune_taxa(tmp_goodTaxa, ps_no_chloro)
ps_no_euk
saveRDS(ps_no_euk, "files/data-prep/rdata/ssu_ps_no_euk.rds")
```

```{r echo=FALSE, eval=TRUE}
ps_no_euk
```

The code removed an additional **`r ntaxa(ps_no_chloro) - ntaxa(ps_no_euk)` Eukaryota ASVs** from the `ps` object.

### Remove any Kingdom NAs

Here we can just use the straight up `subset_taxa` command since we do not need to worry about any ranks above Kingdom also being removed.

```{r}
ps_filt <- subset_taxa(ps_no_euk, !is.na(Kingdom))
saveRDS(ps_filt, "files/data-prep/rdata/ssu_ps_filt.rds")
```


```{r}
ps_work_o <- ps_filt
```

The code eliminated an additional **`r ntaxa(ps_no_euk) - ntaxa(ps_filt)` Kingdom level NA ASVs** from the phyloseq object.

## Rename *NA* taxonomic ranks

Phyloseq has an odd way of dealing with taxonomic ranks that have no value---in other words,  *NA* in the tax table. The first thing we are going to do before moving forward is to change all of the *NA*s to have a value of the next highest classified rank. For example, `ASV26` is not classified at the Genus level but is at Family level (Xanthobacteraceae). So we change the Genus name to *Family_Xanthobacteraceae*. The code for comes from these two posts on the phyloseq GitHub, both by [MSMortensen](https://github.com/MSMortensen): issue [#850](https://github.com/joey711/phyloseq/issues/850#issuecomment-394771087) and issue [#990](https://github.com/joey711/phyloseq/issues/990#issuecomment-424618425).

> One thing this code does is reassign the functions `class` and `order` to taxonomic ranks. This can cause issues if you need these functions.

So you need to run something like this `rm(class, order, phylum, kingdom)` at the end of the code to remove these as variables. For now, I have not come up with a better solution.

```{r}
tax.clean <- data.frame(tax_table(ps_filt))
for (i in 1:6){ tax.clean[,i] <- as.character(tax.clean[,i])}
tax.clean[is.na(tax.clean)] <- ""

for (i in 1:nrow(tax.clean)){
    if (tax.clean[i,2] == ""){
        kingdom <- base::paste("k_", tax.clean[i,1], sep = "")
        tax.clean[i, 2:6] <- kingdom
    } else if (tax.clean[i,3] == ""){
        phylum <- base::paste("p_", tax.clean[i,2], sep = "")
        tax.clean[i, 3:6] <- phylum
    } else if (tax.clean[i,4] == ""){
        class <- base::paste("c_", tax.clean[i,3], sep = "")
        tax.clean[i, 4:6] <- class
    } else if (tax.clean[i,5] == ""){
        order <- base::paste("o_", tax.clean[i,4], sep = "")
        tax.clean[i, 5:6] <- order
    } else if (tax.clean[i,6] == ""){
        tax.clean$Genus[i] <- base::paste("f",tax.clean$Family[i], sep = "_")
        }
}
tax_table(ps_filt) <- as.matrix(tax.clean)
rank_names(ps_filt)
rm(class, order, phylum, kingdom, tax.clean)
saveRDS(ps_filt, "files/data-prep/rdata/ssu_ps_filt.rds")
```

Still the same ranks. That's good. What about the new taxa? Let's take a peak at some families.

```{r, eval=TRUE}
head(get_taxa_unique(ps_filt, "Family"), 16)
```

Nice. Bye-bye *NA*

> *Note*. The original code (mentioned above) was written for data sets that have *species-level* designations.

Since this data set does not contain species, I modified the code to stop at the genus level. If your data set has species, my modifications will not work for you.

Finally, we rename the ps object. This is now our working data set.

```{r}
ps_work <- ps_filt
```

## Add Phylogenetic Tree

One final task is to add a phylogenetic tree to the phyloseq object.

```{r}
ps_work_tree <- rtree(ntaxa(ps_work), rooted = TRUE,
                      tip.label = taxa_names(ps_work))
ps_work <- merge_phyloseq(ps_work,
                          sample_data,
                          ps_work_tree)
ps_work_o_tree <- rtree(ntaxa(ps_work_o), rooted = TRUE,
                      tip.label = taxa_names(ps_work_o))
ps_work_o <- merge_phyloseq(ps_work_o,
                          sample_data,
                          ps_work_o_tree)
saveRDS(ps_work, "files/data-prep/rdata/ssu_ps_work.rds")
saveRDS(ps_work_o, "files/data-prep/rdata/ssu_ps_work_o.rds")
```

## Sample Summary

Now we can summarize the data set so far. Let's start with the working phyloseq object using the `summarize_phyloseq` from the [microbiome R package](https://github.com/microbiome/microbiome/) [@lahti2017microbiome] as we did above.

```{r, echo=FALSE}
min_read_ps_work <- min(readcount(ps_work))
max_read_ps_work <- max(readcount(ps_work))
total_reads_ps_work <- sum(readcount(ps_work))
mean_reads_ps_work <- round(mean(readcount(ps_work)), digits = 0)
median_reads_ps_work <- median(readcount(ps_work))
total_asvs_ps_work <- ntaxa(ps_work)
singleton_ps_work <- tryCatch(ntaxa(rare(ps_work,
                                         detection = 1,
                                         prevalence = 0)),
                              error=function(err) NA)
singleton_ps_work_perc <- tryCatch(round((100*(ntaxa(rare(
  ps_work, detection = 1, prevalence = 0)) / ntaxa(ps_work))), digits = 3),
  error=function(err) NA)
sparsity_ps_work <- round(length(which(
  abundances(ps_work) == 0))/length(abundances(ps)), digits = 3)
```

| Metric                              | Results                                                   |
|-------------------------------------|-----------------------------------------------------------|
| Min. number of reads                | `r min_read_ps_work`                                      |
| Max. number of reads                | `r max_read_ps_work`                                      |
| Total number of reads               | `r total_reads_ps_work`                                   |
| Average number of reads             | `r mean_reads_ps_work`                                    |
| Median number of reads              | `r median_reads_ps_work`                                  |
| Sparsity                            | `r sparsity_ps_work`                                      |
| Any ASVs sum to 1 or less?          | `r isTRUE(singleton_ps_work >= 1)`                        |
| Number of singleton ASVs            | `r singleton_ps_work`                                     |
| Percent of ASVs that are singletons | `r singleton_ps_work_perc`                                |
| Number of sample variables are:     | `r length(sample_data(ps_work))`    (`r colnames(samdf)`) |

We can also generate a summary table of total reads & ASVs for each sample. You can sort the table, download a copy, or filter by search term. Here is the code to generate the data for the table. First, we create data frames that hold total reads and ASVs for each sample.

```{r}
tmp_total_reads <- sample_sums(ps_work)
tmp_total_reads <- as.data.frame(tmp_total_reads, make.names = TRUE)
tmp_total_reads <- tmp_total_reads %>% rownames_to_column("Sample_ID")

tmp_total_asvs <- estimate_richness(ps_work,
                                measures = "Observed")
tmp_total_asvs <- tmp_total_asvs %>% rownames_to_column("Sample_ID")
tmp_total_asvs$Sample_ID <- gsub('\\.', '-', tmp_total_asvs$Sample_ID)
objects()
```

And then we merge these two data frames with the sample data frame.

```{r}
sam_details <- samdf
rownames(sam_details) <- NULL
colnames(sam_details) <- c("Sample_ID", "LOC", "SITE", "TRAN",
                                  "YEAR", "AGE", "TREAT")
## REMOVE LOW COUNT SAMPLE
sam_details <- sam_details[sam_details$Sample_ID != "AR_S14_T219_Y1_YNG_NP", ]

joined_percent <- joined_tab
joined_percent <- joined_percent[joined_percent$Sample_ID != "AR_S14_T219_Y1_YNG_NP", ]
joined_percent[, 2:8] <- NULL

tmp_tab1 <- dplyr::left_join(sam_details, tmp_total_reads) %>%
                left_join(., joined_percent)

tmp_tab2 <- dplyr::left_join(sam_details, tmp_total_reads) %>%
                left_join(., tmp_total_asvs) %>%
                left_join(., tmp_tab1)

reads_lost <- tmp_tab2$nochim - tmp_tab2$tmp_total_reads 
asvs_lost <- tmp_tab2$total_asvs - tmp_tab2$Observed 
tmp_tab2$reads_lost <- reads_lost
tmp_tab2$asvs_lost <- asvs_lost

ssu_sample_summary_final <- tmp_tab2[, c(1:9,14,15)]
colnames(ssu_sample_summary_final) <- c("Sample_ID", "LOC", "SITE",
                          "TRAN", "YEAR", "AGE",
                          "TREAT", "total_reads", "total_ASVs", 
                          "reads_lost", "ASVs_lost")


```

```{r, echo=FALSE, eval=TRUE}
ssu_sample_summary_final <- na.omit(ssu_sample_summary_final)  
```

<small>`r caption_tab_ssu("ssu_sample_summary_final")`</small>

```{r eval=TRUE, echo=FALSE, layout="l-body"}
download_this_fun(ssu_sample_summary_final)
```

```{r, echo=FALSE, layout="l-body-outset", eval=TRUE}
seq_summary_final(seq_table)
rm(seq_table)
```

## Review

We have a few different options to play with. At this point it is difficult to say which we will use or whether additional objects need to be created. Here is a summary of the objects we have.

The phyloseq object *before* removing contaminants, changing ranks, removing NC and/or low-count samples, etc. This  is the *raw* phyloseq object.

```{r, eval=TRUE}
ps
head(get_taxa_unique(ps, "Family"), 16)
```

The phyloseq object *after* removing NC/low-count samples but *before* changing NA ranks.

```{r}
ps_work_o
head(get_taxa_unique(ps_work_o, "Family"), 16)
```

The phyloseq object *after* removing NC/low count samples and *after* changing NA ranks.

```{r, eval=TRUE}
ps_work
head(get_taxa_unique(ps_work, "Family"), 16)
```

## Final Steps

The last thing tasks to complete are to **a**) save copies of the taxonomy and sequence tables and **b**) save an image of the workflow for the next section.

```{r}
write.table(tax_table(ps_work),
            "files/data-prep/tables/ssu_work_tax_table.txt",
            sep="\t", quote = FALSE, col.names=NA)
write.table(t(otu_table(ps_work)),
            "files/data-prep/tables/ssu_work_seq_table.txt",
            sep="\t", quote = FALSE, col.names=NA)
write.table(tax_table(ps_work_o),
            "files/data-prep/tables/ssu_work_o_tax_table.txt",
            sep="\t", quote = FALSE, col.names=NA)
write.table(t(otu_table(ps_work_o)),
            "files/data-prep/tables/ssu_work_o_seq_table.txt",
            sep="\t", quote = FALSE, col.names=NA)
```

```{r, echo=FALSE}
## REMOVE unwanted objects
rm(list = ls(pattern = "^ps_"))
rm(ps)
rm(tax_silva)
rm(list = ls(pattern = "tmp_"))
objects()
```

```{r, echo=FALSE}
# PAGE BUILD
save.image("page_build/data_prep_ssu_wf.rdata")
```

```{r include=FALSE, eval=TRUE}
remove(list = ls())
```

# ITS

```{r, message=FALSE, results = 'hide', eval=TRUE, echo=FALSE}
### COmmon formatting scripts
### NOTE: captioner.R must be read BEFORE captions_XYZ.R
remove(list = ls())	
source("assets/captioner/captioner.R")
source("assets/captioner/captions/captions_data_prep_its.R")
source("assets/reactable/download_this_fun.R")
source("assets/reactable/styles.R")
source("assets/reactable/table_functions/data_prep.R")
```


```{r, include=FALSE, eval=TRUE}
## ONLY FOR PAGE BUILD	
load("page_build/data_prep_its_wf.rdata")	

## READ IN all phyloseq objects	
ps <- readRDS("files/data-prep/rdata/its_ps.rds")
ps_no_nc_check_df <- readRDS("files/data-prep/rdata/its_ps_no_nc_check_df.rds")
ps_filt_nc <- readRDS("files/data-prep/rdata/its_ps_filt_nc.rds")
ps_filt_no_low <- readRDS("files/data-prep/rdata/its_ps_filt_no_low.rds")
ps_filt_rem_asvs <- readRDS("files/data-prep/rdata/its_ps_filt_rem_asvs.rds")

ps_filt_no_nc <- readRDS("files/data-prep/rdata/its_ps_filt_no_nc.rds")
ps_work <- readRDS("files/data-prep/rdata/its_ps_work.rds")
ps_work_o <- readRDS("files/data-prep/rdata/its_ps_work_o.rds")
ps_no_nc_check_t <- readRDS("files/data-prep/rdata/its_ps_no_nc_check_t.rds")

ps_filt <- readRDS("files/data-prep/rdata/its_ps_filt.rds")
```


## Prerequisites

In order to run this workflow, you either need to run the corresponding [DADA2 Workflow for 2018 ITS](agua-dada2.html#s-rrna-data) or begin with the output from that workflow, `data_prep_its_wf.rdata`. See the [Data Availability](data-availability.html) page for complete details.

Unless otherwise noted, we primarily use [phyloseq](https://joey711.github.io/phyloseq/)  [@mcmurdie2013phyloseq] in this section of the workflow to prepare the 2018 ITS data set for community analyses. We prepare the data set by curating samples, removing contaminants, and creating phyloseq objects.

## Sample Summary

Before we begin, let's create a summary table containing some basic sample metadata and the read count data from the [DADA2 workflow](dada2-agua.html#s-rrna-data.html). We need to inspect how total reads changed through the workflow. While we are at it, let's create more intuitive Sample IDs. For more details on how reads changed at each step of the workflow, see the [summary table](dada2-agua.html#track-reads-through-workflow) at the end of the DADA2 section. Table headers are as follows:

| Header            | Description                                                                                    |
|-------------------|------------------------------------------------------------------------------------------------|
| `Sample ID`       | the new sample ID based on Location + Site + Transect + Sampling Year + Forest Age + Treatment |
| `FastqID`         | base name of the fastq file                                                                    |
| `Location`        | Primary sampling location                                                                      |
| `Site`            | within location site                                                                           |
| `Transect`        | within site transect                                                                           |
| `Year`            | the year of sampling (Y0, Y1,  Y4)                                                             |
| `forest age code` | Forest age category (NEW, YNG, OLD)                                                            |
| `Forest age`      | maturity of forest stand                                                                       |
| `Treatment`       | control, +N, +P, or +NP                                                                        |
| `input reads`     | Total number of reads at start of dada2 pipeline                                               |
| `final reads`     | Total number of reads at end of dada2 pipeline                                                 |
| `perc_remain`     | percent of reads remaining from `input` to `final`                                             |
| `no. ASVs`        | Total number of ASVs at end of dada2 pipeline                                                  |

> Note: There are two negative control samples in this data set, `NC_SNC_TNCX_Y0_NCX_X` & `NC_SNC_TNCX_Y4_NCX_X`.
<br/>

```{r, echo=FALSE, eval=FALSE}
remove(list = ls())
tmp_tab1 <- read.table(
  "files/dada2/tables/its_sample_seq_info.txt", header = TRUE, sep = "\t")
tmp_tab1$root <- gsub("_.*", "", tmp_tab1$Fastq_ID_Forward)
tmp_tab2 <- read.table(
  "files/dada2/tables/its_read_changes.txt", header = TRUE,  sep = "\t")
tmp_tab <- left_join(tmp_tab1, tmp_tab2, by = c("Sample_ID"))
tmp_tab$New_ID <- base::paste(tmp_tab$loc_code,
                                   tmp_tab$Site, sep = "_")
tmp_tab$New_ID <- base::paste(tmp_tab$New_ID,
                                   tmp_tab$Transect, sep = "_")
tmp_tab$New_ID <- base::paste(tmp_tab$New_ID,
                                   tmp_tab$year_code, sep = "_")
tmp_tab$New_ID <- base::paste(tmp_tab$New_ID,
                                    tmp_tab$forest_age_code, sep = "_")
tmp_tab$New_ID <- base::paste(tmp_tab$New_ID,
                                   tmp_tab$Treatment, sep = "_")
tmp_tab[duplicated(tmp_tab[,c('New_ID')]),]
tmp_tab <- tmp_tab %>% tibble::column_to_rownames("New_ID")
tmp_tab$Sample_ID <- NULL
tmp_tab <- tmp_tab %>% tibble::rownames_to_column("Sample_ID")

tmp_tab[, c(6, 9:13, 15, 18:(ncol(tmp_tab)-2))] <- NULL
tmp_tab <- tmp_tab[, c(1,9,2,5,3,10,8,4,6,7,11,12)]
load("files/dada2/rdata/its_dada2_wf.rdata")
tmp_df <- data.frame(seqtab)
tmp_asv <- data.frame(rowSums(tmp_df[] > 0))
tmp_asv <- tmp_asv %>% tibble::rownames_to_column("root") %>%
  dplyr::rename("total_asvs" = 2)
tmp_tab2 <- left_join(tmp_tab, tmp_asv, by = c("root"))
tmp_tab2 <- tmp_tab2 %>% dplyr::rename("FastqID" = 2, "Year" = 6)

write.table(tmp_tab2, "files/data-prep/tables/its_summary_table.txt", quote = FALSE, sep = "\t", row.names = FALSE)
rm(list = ls(pattern = "tmp_"))
```

```{r, echo=FALSE, eval=TRUE}
joined_tab <- read.table("files/data-prep/tables/its_summary_table.txt", header = TRUE)
its_summary_table <- read.table("files/data-prep/tables/its_summary_table.txt", header = TRUE)
```

<small>`r caption_tab_its("its_summary_table")`</small>

```{r eval=TRUE, echo=FALSE, layout="l-page"}
download_this_fun(its_summary_table)
```

```{r, echo=FALSE, layout="l-page", eval=TRUE}
sample_summary_table(seq_table)
rm(seq_table)
```

## Defining Groups

1. Load the data packet produced in the final step of the DADA2 workflow. This packet (`its_dada2_wf.rdata`) contains the ASV-by-sample table and the ASV taxonomy table.

2. Rename the samples so names have plot and Depth info.

3. After we load the data packet, we next need to format sample names and define groups.

```{r}
#tmp_tab <- joined_tab[order(joined_tab$FastqID), ]
identical(joined_tab$FastqID, rownames(seqtab))
tmp_new_names <- joined_tab$Sample_ID
rownames(seqtab) <- tmp_new_names

samples.out <- rownames(seqtab)

sample_name <- substr(samples.out, 1, 999)	
loc <- substr(samples.out, 0, 2)	
site <- substr(samples.out, 4, 6)	
tran <- substr(samples.out, 8, 11)	
year <- substr(samples.out, 13, 14)	
age <- substr(samples.out, 16, 18)	
treat <- substr(samples.out, 20, 999)
```

Here is a breakdown of the samples based on the new name: 

- **`r length(unique(sample_name))-2`** samples.   	
- **`r length(unique(loc))-1`** locations.   	
- **`r length(unique(site))-1`** sites.  	
- **`r length(unique(tran))-1`** transects.  	
- **`r length(unique(year))`** sample years.  	
- **`r length(unique(age))-1`** forest ages.   	
- **`r length(unique(treat))-1`** different nutrient treatments.  	
 
We can also take a look at the number of samples per metadata category. 

```{r, echo=FALSE}
tmp_joined_tab <- joined_tab

tmp_joined_tab$Sample_ID <- dplyr::recode(tmp_joined_tab$Sample_ID, 
                                      NC_SNC_TNCX_Y0_NCX_X = "Negative_Y0") %>%
                     dplyr::recode(., NC_SNC_TNCX_Y4_NCX_X = "Negative_Y4")

tmp_joined_tab <- subset(tmp_joined_tab, Sample_ID!="Negative_Y0") %>%
                  subset(., Sample_ID!="Negative_Y4")
       
tmp_year <- data.frame(table(tmp_joined_tab$Year))
tmp_year$type <- "Year"
tmp_site <- data.frame(table(tmp_joined_tab$Site))
tmp_site$type <- "Site"
tmp_trans <- data.frame(table(tmp_joined_tab$Transect))
tmp_trans$type <- "Transect"
tmp_loc <- data.frame(table(tmp_joined_tab$Location))
tmp_loc$type <- "Location"
tmp_treat <- data.frame(table(tmp_joined_tab$Treatment))
tmp_treat$type <- "Treatment"
tmp_age <- data.frame(table(tmp_joined_tab$Forest_age))
tmp_age$type <- "Forest_age"

md_summary <- rbind(tmp_year, tmp_loc, tmp_treat, tmp_age, tmp_site, tmp_trans)
md_summary <- md_summary[,c(3,1,2)]
md_summary <- md_summary %>% dplyr::rename("variable" = 2) %>% 
                             dplyr::rename(., "category" = 1) %>% 
                             dplyr::rename(., "count" = 3)
```


```{r, echo=FALSE, eval=TRUE}
its_metadata_summary <- md_summary 
```

<small>`r caption_tab_its("its_metadata_summary")`</small>

```{r eval=TRUE, echo=FALSE, layout="l-body"}
download_this_fun(its_metadata_summary)
```

```{r, echo=FALSE, layout="l-body", eval=TRUE}
metadata_summary_table(seq_table)
rm(seq_table)
```

<br/>

4. And finally we define a sample data frame that holds the different groups we extracted from the sample names.

```{r}
#define a sample data frame
samdf <- data.frame(SamName = sample_name,
                    LOC = loc,
                    SITE = site,
                    TRAN = tran,
                    YEAR = year,
                    AGE = age,
                    TREAT = treat)
rownames(samdf) <- samples.out
```

## Create a Phyloseq Object

###  Fix Taxon Names

The UNITE database we used for classification adds a little prefix to every rank call, like `k__` for Kingdom, `o__` for Order, etc. To keep in step with our other analyses, we will remove these tags. Of course, we also make a ps object with the original names just in case. At this point we will also remove the Species rank since it is essentially useless.

<aside>
*I KNOW there is an easier way to do this*.
</aside>

```{r}
tax_mod_o <- data.frame(tax)
tax_mod_o$Species <- NULL
tax_mod_o <- as.matrix(tax_mod_o)
tax_mod <- sub("k__", "", tax_mod_o)
tax_mod <- sub("p__", "", tax_mod)
tax_mod <- sub("c__", "", tax_mod)
tax_mod <- sub("o__", "", tax_mod)
tax_mod <- sub("f__", "", tax_mod)
tax_mod <- sub("g__", "", tax_mod)
```

**A**. The first step is to rename the amplicon sequence variants (ASVs) so the designations are a bit more user friendly. By default, DADA2 names each ASV by its unique sequence so that data can be directly compared across studies (which is great). But this convention can get cumbersome downstream, so we rename the ASVs using a simpler convention---ASV1, ASV2, ASV3, and so on.

<aside>
A phyloseq object contains ASV table (taxa abundances), sample metadata, and taxonomy table (mapping between ASVs and higher-level taxonomic classifications).
</aside>

```{r}
# this create the phyloseq object
ps <- phyloseq(otu_table(seqtab, taxa_are_rows = FALSE),
                   sample_data(samdf), tax_table(tax_mod))
tax_table(ps) <- cbind(tax_table(ps),
                           rownames(tax_table(ps)))

# adding unique ASV names
taxa_names(ps) <- paste0("ASV", seq(ntaxa(ps)))
tax_table(ps) <- cbind(tax_table(ps),
                           rownames(tax_table(ps)))
```


```{r echo=FALSE, eval=TRUE}
head(taxa_names(ps))
```

So the complete data set contains `r ntaxa(ps)` ASVs. We can also use the [microbiome R package](https://github.com/microbiome/microbiome/)  [@lahti2017microbiome] to get some additional summary data from the phyloseq object.

```{r, echo=FALSE}
min_read_ps <- min(readcount(ps))
max_read_ps <- max(readcount(ps))
total_reads_ps <- sum(readcount(ps))
mean_reads_ps <- round(mean(readcount(ps)), digits = 0)
median_reads_ps <- median(readcount(ps))
total_asvs_ps <- ntaxa(ps)
singleton_ps <- tryCatch(ntaxa(rare(ps, detection = 1, prevalence = 0)), error=function(err) NA)
singleton_ps_perc <- tryCatch(round((100*(ntaxa(rare(ps, detection = 1, prevalence = 0)) /
                                   ntaxa(ps))), digits = 3), error=function(err) NA)
sparsity_ps <- round(length(which(abundances(ps) == 0))/length(abundances(ps)),
                     digits = 3)
```

| Metric                              | Results                                              |
|-------------------------------------|------------------------------------------------------|
| Min. number of reads                | `r min_read_ps`                                      |
| Max. number of reads                | `r max_read_ps`                                      |
| Total number of reads               | `r total_reads_ps`                                   |
| Average number of reads             | `r mean_reads_ps`                                    |
| Median number of reads              | `r median_reads_ps`                                  |
| Sparsity                            | `r sparsity_ps`                                      |
| Any ASVs sum to 1 or less?          | `r isTRUE(singleton_ps >= 1)`                        |
| Number of singleton ASVs            | `r singleton_ps`                                     |
| Percent of ASVs that are singletons | `r singleton_ps_perc`                                |
| Number of sample variables are:     | `r length(sample_data(ps))`    (`r colnames(samdf)`) |

**B**. Add two final columns containing the ASV sequences and ASV IDs. This will be useful later when trying to export a fasta file. We can also take a look at the phyloseq object.

```{r}
colnames(tax_table(ps)) <- c("Kingdom", "Phylum", "Class", "Order",
    "Family", "Genus", "ASV_SEQ", "ASV_ID")
ps
```

```{r, echo=FALSE, eval=TRUE}
ps
rank_names(ps)
```

**C**. Export sequence and taxonomy tables for the unadulterated phyloseq object for later use. We will use the prefix `full` to indicate that these are the *raw* outputs.

```{r}
write.table(tax_table(ps),
            "files/data-prep/tables/its_full_tax_table.txt",
            sep="\t", quote = FALSE, col.names=NA)
write.table(t(otu_table(ps)),
            "files/data-prep/tables/its_full_seq_table.txt",
            sep="\t", quote = FALSE, col.names=NA)
saveRDS(ps, "files/data-prep/rdata/its_ps.rds")	            
```

At this point we would normally remove unwanted taxa. Since we do not have any of these for this data set, we are going to save the phyloseq object with a new name. That way, if we do decide later on to remove some taxa it will be easier to plug in the code here and then continue with the rest of the workflow.

```{r}
ps_filt <- ps
saveRDS(ps_filt, "files/data-prep/rdata/its_ps_filt.rds")
```

## Remove Negative Control (NC) Samples

We know the NC had **a lot** reads---when we started the DADA2 workflow. We need to remove the NC *and* all of the ASVs only found in those sample. So how many ASVs are in the NC?

```{r}
ps_filt_nc <- prune_samples(c("NC_SNC_TNCX_Y0_NCX_X", "NC_SNC_TNCX_Y4_NCX_X"), 
                            ps_filt)
ps_filt_nc <- prune_taxa(taxa_sums(ps_filt_nc) > 0, ps_filt_nc)
tax_table_nc <- tax_table(ps_filt_nc)
saveRDS(ps_filt_nc, "files/data-prep/rdata/its_ps_filt_nc.rds")
```

```{r, eval=TRUE}
ps_filt_nc
```

Looks like there are `r ntaxa(ps_filt_nc)` ASVs in the NC from a total of `r sum(otu_table(ps_filt_nc))` reads.

```{r remove_nc_2}
nc_asvs <- row.names(tax_table_nc)
nc_asvs
```

```{r echo=FALSE, eval=TRUE}
nc_asvs
```

Hum. ASVs are numbered in order by total abundance in the data set so we know that some of the ASVs in the Negative Control are abundant in the dataset. We can look at the abundance of these ASVs across all samples and compare it to the NC.

```{r}
ps_no_nc_check <- prune_taxa(nc_asvs, ps_filt)
ps_no_nc_check_df <- data.frame(otu_table(t(ps_no_nc_check)))
saveRDS(ps_no_nc_check_df, "files/data-prep/rdata/its_ps_no_nc_check_df.rds")

ps_no_nc_check_t <- ps_no_nc_check_df %>% tibble::rownames_to_column("ASV_ID")

ps_no_nc_check_t <- ps_no_nc_check_t  %>% 
           mutate(
             total_reads_NC = rowSums(select(., contains("NC_SNC_TNCX_"))), 
             .after = "ASV_ID"
             )

ps_no_nc_check_t$NC_SNC_TNCX_Y0_NCX_X <- NULL
ps_no_nc_check_t$NC_SNC_TNCX_Y4_NCX_X <- NULL

ps_no_nc_check_t <- ps_no_nc_check_t %>%
  dplyr::mutate(total_reads = rowSums(.[3:ncol(ps_no_nc_check_t)]), .after = "total_reads_NC")

ps_no_nc_check_t[, 4:ncol(ps_no_nc_check_t)] <- list(NULL)
ps_no_nc_check_t <- ps_no_nc_check_t %>%
  dplyr::mutate(perc_in_neg = 100*( total_reads_NC / (total_reads_NC + total_reads)),
                .after = "total_reads")
saveRDS(ps_no_nc_check_t, "files/data-prep/rdata/its_ps_no_nc_check_t.rds")
```

```{r, eval=TRUE}
ps_no_nc_check_t <- readRDS("files/data-prep/rdata/its_ps_no_nc_check_t.rds")
ps_no_nc_check_df <- readRDS("files/data-prep/rdata/its_ps_no_nc_check_df.rds")

tmp_1 <- data.frame(rowSums(ps_no_nc_check_df != 0) - 1)
tmp_2 <- data.frame(ps_no_nc_check_df$NC_SNC_TNCX_Y0_NCX_X)
tmp_3 <- data.frame(ps_no_nc_check_df$NC_SNC_TNCX_Y4_NCX_X)
ps_no_nc_check_t <- cbind(ps_no_nc_check_t, tmp_1, tmp_2, tmp_3)
ps_no_nc_check_t$perc_in_neg <- round(ps_no_nc_check_t$perc_in_neg, digits = 3)
ps_no_nc_check_t <- ps_no_nc_check_t %>% dplyr::rename("Num samp" = 5) %>%
                   dplyr::rename("reads Y0 NC" = 6) %>%
                   dplyr::rename("reads Y4 NC" = 7) %>%
                   dplyr::rename("reads NC" = 2) %>%
                   dplyr::rename("reads non NC" = 3)  
ps_no_nc_check_t$ASV_ID <- NULL
ps_no_nc_check_t <- ps_no_nc_check_t %>% tibble::rownames_to_column("ASV_ID")
```

```{r, echo=FALSE, eval=TRUE}
its_negative_control_check <- ps_no_nc_check_t
```

<small>`r caption_tab_its("its_negative_control_check")`</small>

```{r eval=TRUE, echo=FALSE, layout="l-body-outset"}
download_this_fun(its_negative_control_check)
```

```{r, echo=FALSE, layout="l-body-outset", eval=TRUE}
neg_control_check(seq_table)
rm(seq_table)
```


Clearly,  ASV717, ASV874, ASV1549, ASV6007, ASV7299, ASV7946, and ASV32304 are only (or almost only) found in the NC. We can definitely get rid of those. Since ASV4 and ASV97 are represented by only 5 reads total, those can stay. So that leaves ASV423 and ASV429, both of which are found in ~30 samples and both represented by more reads in the NC than the rest of the samples. Neither ASVs was not found in the Year 0 NC, just Year 4. Since there were so many more reads in the NC, and these are not very dominant ASVs anyway, we can ditch these too.

OK, now let's use the `prune_taxa` command with this list to remove  the NC ASVs from our main phyloseq object.

```{r}
asv_remove <- c("ASV423", "ASV429", "ASV717", "ASV874", "ASV1549", 
                "ASV6007", "ASV7299", "ASV7946", "ASV32304")
asv_remove <- as.factor(asv_remove)
goodTaxa2 <- setdiff(taxa_names(ps_filt), asv_remove)
ps_filt_rem_asvs <- prune_taxa(goodTaxa2, ps_filt)
```

```{r, eval=FALSE}
ps_filt_rem_asvs
saveRDS(ps_filt_rem_asvs, "files/data-prep/rdata/its_ps_filt_rem_asvs.rds")
ntaxa(ps_filt) - ntaxa(ps_filt_rem_asvs)
```

Perfect. Confirm that **`r ntaxa(ps_filt) - ntaxa(ps_filt_rem_asvs)`** ASVs were removed. Check. How many reads did we lose from the rest of the data set when we removed those ASVs? **`r sum(otu_table(ps_filt)) - sum(otu_table(ps_filt_rem_asvs)) - sum(otu_table(ps_filt_nc))`**.

*Now* the NC sample can be removed from the data set. 

```{r remove_nc_4, results = 'markdown', eval=FALSE}
ps_filt_no_nc <- subset_samples(ps_filt_rem_asvs, 
                                SamName != c("NC_SNC_TNCX_Y0_NCX_X", 
                                             "NC_SNC_TNCX_Y4_NCX_X"))
ps_filt_no_nc <- saveRDS(ps_filt_no_nc, "files/data-prep/rdata/its_ps_filt_no_nc.rds")
```

After removing samples we need to check whether any ASVs ended up with no reads.

```{r}
ps_filt_no_nc
no_reads <- taxa_sums(ps_filt_no_nc) == 0
sum(no_reads)
```

All good.

## Remove Low-Count Samples

Next, we can remove samples with really low read counts---here we set the threshold to 15,000 reads.

```{r, results = 'markdown'}
ps_filt_no_low <- prune_samples(sample_sums(ps_filt_no_nc) > 15000, ps_filt_no_nc)
```

We lost `r nsamples(ps_filt_no_nc) - nsamples(ps_filt_no_low)` sample(s). After removing samples we need to check whether any ASVs ended up with no reads.

```{r}
no_reads <- taxa_sums(ps_filt_no_low) == 0
sum(no_reads)
```

And we lost `r sum(no_reads)` ASV(s). So now we must remove these from the ps object.

```{r}
ps_filt_no_low <- prune_taxa(taxa_sums(ps_filt_no_low) > 0, ps_filt_no_low)
saveRDS(ps_filt_no_low, "files/data-prep/rdata/its_ps_filt_no_low.rds")
```

```{r, eval=TRUE}
ps_filt_no_low
```

## Rename *NA* taxonomic ranks

Phyloseq has an odd way of dealing with taxonomic ranks that have no value---in other words,  *NA* in the tax table. The first thing we are going to do before moving forward is to change all of the *NA*s to have a value of the next highest classified rank. For example, `ASV4` is not classified at the Genus level but is at Family level (Nitrososphaeraceae). So we change the Genus name to *Family_Nitrososphaeraceae*. The code for comes from these two posts on the phyloseq GitHub, both by [MSMortensen](https://github.com/MSMortensen): issue [#850](https://github.com/joey711/phyloseq/issues/850#issuecomment-394771087) and issue [#990](https://github.com/joey711/phyloseq/issues/990#issuecomment-424618425).

> One thing this code does is reassign the functions `class` and `order` to taxonomic ranks. This can cause issues if you need these functions.

So you need to run something like this `rm(class, order, phylum, kingdom)` at the end of the code to remove these as variables. For now, I have not come up with a better solution.

Before doing that, we will save a copy of the modified phyloseq object with the original taxa names.

```{r}
ps_work_o <- ps_filt_no_low
saveRDS(ps_work_o, "files/data-prep/rdata/its_ps_work_o.rds")
```

```{r }
tax.clean <- data.frame(tax_table(ps_filt_no_low))
for (i in 1:6){ tax.clean[,i] <- as.character(tax.clean[,i])}
tax.clean[is.na(tax.clean)] <- ""
for (i in 1:nrow(tax.clean)){
    if (tax.clean[i,2] == ""){
        kingdom <- base::paste("k_", tax.clean[i,1], sep = "")
        tax.clean[i, 2:6] <- kingdom
    } else if (tax.clean[i,3] == ""){
        phylum <- base::paste("p_", tax.clean[i,2], sep = "")
        tax.clean[i, 3:6] <- phylum
    } else if (tax.clean[i,4] == ""){
        class <- base::paste("c_", tax.clean[i,3], sep = "")
        tax.clean[i, 4:6] <- class
    } else if (tax.clean[i,5] == ""){
        order <- base::paste("o_", tax.clean[i,4], sep = "")
        tax.clean[i, 5:6] <- order
    } else if (tax.clean[i,6] == ""){
        tax.clean$Genus[i] <- base::paste("f",tax.clean$Family[i], sep = "_")
        }
}
tax_table(ps_filt_no_low) <- as.matrix(tax.clean)
rank_names(ps_filt_no_low)
rm(class, order, phylum, kingdom, tax.clean)
```

Still the same ranks. That's good. What about the new groups? Let's take a peak at some families.

```{r, eval=TRUE}
head(get_taxa_unique(ps_filt_no_low, "Family"), 16)
```

Nice. Adios *NA*.

> *Note*. The original code is written for data sets that have species-level designations.

Since this data set does not contain species, I modified the code to stop at the genus level. If your data set has species, my modifications will not work for you.

Finally, we rename the ps object. This is now our working data set.

```{r}
ps_work <- ps_filt_no_low
saveRDS(ps_work, "files/data-prep/rdata/its_ps_work.rds")	
```

Now that we have removed the NC and samples with low reads, we can summarize the data in our working phyloseq object. Let's start with the data set as a whole using the `summarize_phyloseq` from the [microbiome R package](https://github.com/microbiome/microbiome/) [@lahti2017microbiome] as we did above.

```{r, echo=FALSE}
min_read_ps_work <- min(readcount(ps_work))
max_read_ps_work <- max(readcount(ps_work))
total_reads_ps_work <- sum(readcount(ps_work))
mean_reads_ps_work <- round(mean(readcount(ps_work)), digits = 0)
median_reads_ps_work <- median(readcount(ps_work))
total_asvs_ps_work <- ntaxa(ps_work)
singleton_ps_work <- tryCatch(ntaxa(rare(ps_work,
                                         detection = 1,
                                         prevalence = 0)),
                              error=function(err) NA)
singleton_ps_work_perc <- tryCatch(round((100*(ntaxa(rare(ps_work,
                                                          detection = 1,
                                                          prevalence = 0)) /
                                   ntaxa(ps_work))), digits = 3),
                                   error=function(err) NA)
sparsity_ps_work <- round(length(which(abundances(ps_work) == 0))/
                            length(abundances(ps)), digits = 3)
```

| Metric                              | Results                                                  |
|-------------------------------------|----------------------------------------------------------|
| Min. number of reads                | `r min_read_ps_work`                                     |
| Max. number of reads                | `r max_read_ps_work`                                     |
| Total number of reads               | `r total_reads_ps_work`                                  |
| Average number of reads             | `r mean_reads_ps_work`                                   |
| Median number of reads              | `r median_reads_ps_work`                                 |
| Sparsity                            | `r sparsity_ps_work`                                     |
| Any ASVs sum to 1 or less?          | `r isTRUE(singleton_ps_work >= 1)`                       |
| Number of singleton ASVs            | `r singleton_ps_work`                                    |
| Percent of ASVs that are singletons | `r singleton_ps_work_perc`                               |
| Number of sample variables are:     | `r length(sample_data(ps_work))`   (`r colnames(samdf)`) |

We can also generate a summary table of total reads & ASVs for each sample. You can sort the table, download a copy, or filter by search term. Here is the code to generate the data for the table. First, we create data frames that hold total reads and ASVs for each sample.

```{r}
tmp_total_reads <- sample_sums(ps_work)
tmp_total_reads <- as.data.frame(tmp_total_reads, make.names = TRUE)
tmp_total_reads <- tmp_total_reads %>% rownames_to_column("Sample_ID")

tmp_total_asvs <- estimate_richness(ps_work,
                                measures = "Observed")
tmp_total_asvs <- tmp_total_asvs %>% rownames_to_column("Sample_ID")
tmp_total_asvs$Sample_ID <- gsub('\\.', '-', tmp_total_asvs$Sample_ID)
objects()
```

And then we merge these two data frames with the sample data frame.

```{r}
sam_details <- samdf
rownames(sam_details) <- NULL
colnames(sam_details) <- c("Sample_ID", "LOC", "SITE", "TRAN",
                                  "YEAR", "AGE", "TREAT")
joined_percent <- joined_tab
joined_percent[, 2:8] <- NULL
tmp_tab1 <- dplyr::left_join(sam_details, tmp_total_reads) %>%
                left_join(., joined_percent)

tmp_tab2 <- dplyr::left_join(sam_details, tmp_total_reads) %>%
                left_join(., tmp_total_asvs) %>%
                left_join(., tmp_tab1)

reads_lost <- tmp_tab2$nochim - tmp_tab2$tmp_total_reads 
asvs_lost <- tmp_tab2$total_asvs - tmp_tab2$Observed 
tmp_tab2$reads_lost <- reads_lost
tmp_tab2$asvs_lost <- asvs_lost

its_sample_summary_final <- tmp_tab2[, c(1:9,14,15)]
colnames(its_sample_summary_final) <- c("Sample_ID", "LOC", "SITE",
                          "TRAN", "YEAR", "AGE",
                          "TREAT", "total_reads", "total_ASVs", 
                          "reads_lost", "ASVs_lost")
```

```{r, echo=FALSE, eval=TRUE}
its_sample_summary_final <- na.omit(its_sample_summary_final)  
```

<small>`r caption_tab_its("its_sample_summary_final")`</small>

```{r eval=TRUE, echo=FALSE, layout="l-body-outset"}
download_this_fun(its_sample_summary_final)
```

```{r, echo=FALSE, layout="l-body-outset", eval=TRUE}
seq_summary_final(seq_table)
rm(seq_table)
```

## Review

We have a few different options to play with. At this point it is difficult to say which we will use or whether additional objects need to be created. Here is a summary of the objects we have.

The phyloseq object *before* removing contaminants, changing ranks, removing NC and/or low-count samples, etc. This  is the *raw* phyloseq object.

```{r, eval=TRUE}
ps
head(get_taxa_unique(ps, "Family"), 16)
```

The phyloseq object *after* removing NC/low count samples but *before* changing NA ranks.

```{r}
ps_work_o
head(get_taxa_unique(ps_work_o, "Family"), 16)
```

The phyloseq object *after* removing NC/low count samples and *after* changing NA ranks.

```{r, eval=TRUE}
ps_work
head(get_taxa_unique(ps_work, "Family"), 16)
```

## Final Steps

The last thing tasks to complete are to **a**) save copies of the taxonomy and sequence tables and **b**) save an image of the workflow for the next section.

```{r}
write.table(tax_table(ps_work),
            "files/data-prep/tables/its_work_tax_table.txt",
            sep="\t", quote = FALSE, col.names=NA)
write.table(t(otu_table(ps_work)),
            "files/data-prep/tables/its_work_seq_table.txt",
            sep="\t", quote = FALSE, col.names=NA)

write.table(tax_table(ps_work_o),
            "files/data-prep/tables/its_work_o_tax_table.txt",
            sep="\t", quote = FALSE, col.names=NA)
write.table(t(otu_table(ps_work_o)),
            "files/data-prep/tables/its_work_o_seq_table.txt",
            sep="\t", quote = FALSE, col.names=NA)
```


```{r, echo=FALSE}	
## REMOVE unwanted objects	
rm(list = ls(pattern = "^ps_"))	
rm(ps)	
rm(list = c("tax_mod", "sam_tab", "tax", "tax_mod_o", "goodTaxa2"))	
rm(list = ls(pattern = "tmp_"))	
objects()	
```	

```{r, echo=FALSE}	
# PAGE BUILD	
save.image("page_build/data_prep_its_wf.rdata")	
#gdata::keep(obj, samp_data, sure = TRUE)	
#save.image("files/data-prep/rdata/ssu_taxmap.rdata")	
```

```{r include=FALSE, eval=TRUE}
remove(list = ls())
```

That's all for this part!

## Data Availability (16S rRNA) {.appendix}

If you are interested in performing your own analysis, you can find copies of relevant data tables here. *Please note these are the raw data, i.e., non-rarefied or normalized in any way.*

**Full data set**: Before removing contaminants & unwanted taxa. 

- *ASV table* <a href="include/data-prep/ssu_full_seq_table.txt" download="ssu_full_seq_table.txt"> Download the complete ASV by sample table here.</a> This table contains ASV counts for each sample.

- *Taxonomy table*<a href="include/data-prep/ssu_full_tax_table.txt" download="ssu_full_tax_table.txt"> Download the complete classification file here.</a> This table includes the full lineage plus the sequence of each ASV.

**Trimmed data set**: After removing contaminants & unwanted taxa. 

- *ASV table* <a href="include/data-prep/ssu_work_seq_table.txt" download="ssu_work_seq_table.txt"> Download the complete ASV by sample table here.</a> This table contains ASV counts for each sample.

- *Taxonomy table*<a href="include/data-prep/ssu_work_tax_table.txt" download="ssu_work_tax_table.txt"> Download the complete classification file here.</a> This table includes the full lineage plus the sequence of each ASV.

## Data Availability (ITS) {.appendix}

If you are interested in performing your own analysis, you can find copies of relevant data tables here. *Please note these are the raw data, i.e., non-rarefied or normalized in any way.*

**Full data set**: Before removing contaminants & unwanted taxa. 

- *ASV table* <a href="include/data-prep/its_full_seq_table.txt" download="its_full_seq_table.txt"> Download the complete ASV by sample table here.</a> This table contains ASV counts for each sample.

- *Taxonomy table*<a href="include/data-prep/its_full_tax_table.txt" download="its_full_tax_table.txt"> Download the complete classification file here.</a> This table includes the full lineage plus the sequence of each ASV.

**Trimmed data set**: After removing contaminants & unwanted taxa. 

- *ASV table* <a href="include/data-prep/its_work_seq_table.txt" download="its_work_seq_table.txt"> Download the complete ASV by sample table here.</a> This table contains ASV counts for each sample.

- *Taxonomy table*<a href="include/data-prep/its_work_tax_table.txt" download="its_work_tax_table.txt"> Download the complete classification file here.</a> This table includes the full lineage plus the sequence of each ASV.

##  Source Code {.appendix}

You can find the source code for this page by [clicking this link](https://github.com/agua-salud/nutrients/blob/main/data-prep.Rmd).

## Data Availability {.appendix}

Raw fastq files available on figshare at XXXXXXXX. Trimmed fastq files (primers removed) available through the ENA under project accession number [XXXXXXXX](). Output files from this workflow available on figshare at [XXXXXXXX.]().

